{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cfa27ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f6273e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'findspark' from 'C:\\\\Users\\\\W10\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\findspark.py'>\n"
     ]
    }
   ],
   "source": [
    "print(findspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ecde12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1c0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('hai').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1414247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "            .option('header',True) \\\n",
    "            .option('inferSchema',True) \\\n",
    "            .csv(\"C:/Users/W10/Desktop/sparkTxt/annual-csv.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56704b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+-------+----------------------+\n",
      "|Year|Industry_aggregation_NZSIOC|Industry_code_NZSIOC|Industry_name_NZSIOC|             Units|Variable_code|       Variable_name|   Variable_category|  Value|Industry_code_ANZSIC06|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+-------+----------------------+\n",
      "|2020|                    Level 1|               99999|      All industries|Dollars (millions)|          H01|        Total income|Financial perform...|733,258|  ANZSIC06 division...|\n",
      "|2020|                    Level 1|               99999|      All industries|Dollars (millions)|          H04|Sales, government...|Financial perform...|660,630|  ANZSIC06 division...|\n",
      "|2020|                    Level 1|               99999|      All industries|Dollars (millions)|          H05|Interest, dividen...|Financial perform...| 54,342|  ANZSIC06 division...|\n",
      "|2020|                    Level 1|               99999|      All industries|Dollars (millions)|          H07|Non-operating income|Financial perform...| 18,285|  ANZSIC06 division...|\n",
      "|2020|                    Level 1|               99999|      All industries|Dollars (millions)|          H08|   Total expenditure|Financial perform...|654,872|  ANZSIC06 division...|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+-------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,truncate=True, vertical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4eaab2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Industry_aggregation_NZSIOC: string (nullable = true)\n",
      " |-- Industry_code_NZSIOC: string (nullable = true)\n",
      " |-- Industry_name_NZSIOC: string (nullable = true)\n",
      " |-- Units: string (nullable = true)\n",
      " |-- Variable_code: string (nullable = true)\n",
      " |-- Variable_name: string (nullable = true)\n",
      " |-- Variable_category: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      " |-- Industry_code_ANZSIC06: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64f4d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3efd26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "[ \\\n",
    "    StructField(\"Year\", IntegerType(), True), \\\n",
    "    StructField(\"Industry_aggregation_NZSIOC\", StringType(), True), \\\n",
    "    StructField(\"chaddi baniyan\", StringType(), True), \\\n",
    "    StructField(\"Industry_name_NZSIOC\", StringType(), True), \\\n",
    "    StructField(\"Units\", StringType(), True), \\\n",
    "    StructField(\"Variable_code\", StringType(), True), \\\n",
    "    StructField(\"Variable_name\", StringType(), True), \\\n",
    "    StructField(\"Variable_category\", StringType(), True), \\\n",
    "    StructField(\"Value\", StringType(), True), \\\n",
    "    StructField(\"Industry_code_ANZSIC06\", StringType(), True)\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4cc672d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.csv('C:/Users/W10/Desktop/sparkTxt/annual-csv.csv', schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e40bc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+-------------+--------------------+-------+----------------------+\n",
      "|Year|Industry_aggregation_NZSIOC|      chaddi baniyan|Industry_name_NZSIOC|             Units|Variable_code|Variable_name|   Variable_category|  Value|Industry_code_ANZSIC06|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+-------------+--------------------+-------+----------------------+\n",
      "|null|       Industry_aggregat...|Industry_code_NZSIOC|Industry_name_NZSIOC|             Units|Variable_code|Variable_name|   Variable_category|  Value|  Industry_code_ANZ...|\n",
      "|2020|                    Level 1|               99999|      All industries|Dollars (millions)|          H01| Total income|Financial perform...|733,258|  ANZSIC06 division...|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+-------------+--------------------+-------+----------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5cfe06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.write.format('csv').mode('Overwrite').option('maxRecordsPerFile',500).option('path','output').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "90f76ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37081"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cfc82f27",
   "metadata": {},
   "outputs": [],
   "source": [
    " df2.registerTempTable(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64425b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+-------+----------------------+\n",
      "|Year|Industry_aggregation_NZSIOC|      chaddi baniyan|Industry_name_NZSIOC|             Units|Variable_code|       Variable_name|   Variable_category|  Value|Industry_code_ANZSIC06|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+-------+----------------------+\n",
      "|null|       Industry_aggregat...|Industry_code_NZSIOC|Industry_name_NZSIOC|             Units|Variable_code|       Variable_name|   Variable_category|  Value|  Industry_code_ANZ...|\n",
      "|2020|                    Level 1|               99999|      All industries|Dollars (millions)|          H01|        Total income|Financial perform...|733,258|  ANZSIC06 division...|\n",
      "|2020|                    Level 1|               99999|      All industries|Dollars (millions)|          H04|Sales, government...|Financial perform...|660,630|  ANZSIC06 division...|\n",
      "|2020|                    Level 1|               99999|      All industries|Dollars (millions)|          H05|Interest, dividen...|Financial perform...| 54,342|  ANZSIC06 division...|\n",
      "|2020|                    Level 1|               99999|      All industries|Dollars (millions)|          H07|Non-operating income|Financial perform...| 18,285|  ANZSIC06 division...|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+-------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|  testing|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from dfTable').show(5)\n",
    "spark.sql('show databases').show()\n",
    "# spark.sql('create database testing')\n",
    "df2.createOrReplaceTempView('permTabledf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba5eac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "jsondata = requests.request('GET','https://jsonplaceholder.typicode.com/todos/')\n",
    "# print(jsondata.json())\n",
    "j = (jsondata.json())\n",
    "print(type(j))\n",
    "\n",
    "file = open('C:/Users/W10/Desktop/sparkTxt/testing.json','a')\n",
    "for r in j:\n",
    "    file.write(str(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff57908",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a12db1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([\"Project Gutenberg’s\",\n",
    "        \"Alice’s Adventures in Wonderland\",\n",
    "        \"Project Gutenberg’s\",\n",
    "        \"Adventures in Wonderland\",\n",
    "        \"Project Gutenberg’s\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b23e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "898c3f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Project Gutenberg’s',\n",
       " 'Alice’s Adventures in Wonderland',\n",
       " 'Project Gutenberg’s',\n",
       " 'Adventures in Wonderland',\n",
       " 'Project Gutenberg’s']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f438de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd.flatMap(lambda x : x.split(\" \")).map(lambda x : (x,1)).reduceByKey(lambda x,y : x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3bc4a5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gutenberg’s', 3),\n",
       " ('Alice’s', 1),\n",
       " ('in', 2),\n",
       " ('Adventures', 2),\n",
       " ('Wonderland', 2),\n",
       " ('Project', 3)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9d01d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datardd = spark.sparkContext.textFile('C:/Users/W10/Desktop/sparkTxt/spark.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5ef58b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark spark spark spark spark spark spark spark spark spark',\n",
       " 'spark spark spark spark spark spark',\n",
       " 'spark spark spark spark spark spark spark',\n",
       " 'spark',\n",
       " 'spark spark spark',\n",
       " 'spark spark spark spark']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datardd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4970a2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark'],\n",
       " ['spark', 'spark', 'spark', 'spark', 'spark', 'spark'],\n",
       " ['spark', 'spark', 'spark', 'spark', 'spark', 'spark', 'spark'],\n",
       " ['spark'],\n",
       " ['spark', 'spark', 'spark'],\n",
       " ['spark', 'spark', 'spark', 'spark']]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = datardd.map(lambda x : x.split(' '))\n",
    "r2.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "891cf17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "listt=r2.map(lambda x : len(x)).collect()\n",
    "maxele=max(listt)\n",
    "print(maxele)\n",
    "\n",
    "# def x= ['spark', 'spark', 'spark', 'spark', 'spark', 'spark']\n",
    "\n",
    "def addElements(x):\n",
    "    for i in range(maxele):\n",
    "        if len(x) != maxele:\n",
    "            x.append('nodata')\n",
    "        else:\n",
    "            break\n",
    "    return x\n",
    "            \n",
    "r3 = r2.map(lambda x : addElements(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8b770e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark'],\n",
       " ['spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata'],\n",
       " ['spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata'],\n",
       " ['spark',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata'],\n",
       " ['spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata'],\n",
       " ['spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'spark',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata',\n",
       "  'nodata']]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6db6cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=r3.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "284b5303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+------+------+------+------+------+\n",
      "|   _1|    _2|    _3|    _4|    _5|    _6|    _7|    _8|    _9|   _10|\n",
      "+-----+------+------+------+------+------+------+------+------+------+\n",
      "|spark| spark| spark| spark| spark| spark| spark| spark| spark| spark|\n",
      "|spark| spark| spark| spark| spark| spark|nodata|nodata|nodata|nodata|\n",
      "|spark| spark| spark| spark| spark| spark| spark|nodata|nodata|nodata|\n",
      "|spark|nodata|nodata|nodata|nodata|nodata|nodata|nodata|nodata|nodata|\n",
      "|spark| spark| spark|nodata|nodata|nodata|nodata|nodata|nodata|nodata|\n",
      "|spark| spark| spark| spark|nodata|nodata|nodata|nodata|nodata|nodata|\n",
      "+-----+------+------+------+------+------+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f23b794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew = spark.read \\\n",
    "                .option('header',True) \\\n",
    "                .csv('C:/Users/W10/Desktop/sparkTxt/rating2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f3ebadfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+---------+\n",
      "|userId|movieId|rating| timestamp|ratingStr|\n",
      "+------+-------+------+----------+---------+\n",
      "|     1|     39|   2.6|1260759144|      one|\n",
      "|     1|     38|   2.7|      null|      two|\n",
      "|     1|   null|   2.7|1260759140|    three|\n",
      "|  null|     36|   3.8|1260759149|     null|\n",
      "|     1|     35|   4.9|1260759148|     five|\n",
      "|     1|   null|     5|      null|     null|\n",
      "|  null|     33|   3.1|1260759146|    seven|\n",
      "|     1|     32|  null|1260759145|    eight|\n",
      "+------+-------+------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfnew.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f23b5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "dfnew = dfnew.na.drop()\n",
    "# dfnew.show()\n",
    "\n",
    "def f2(x):\n",
    "    return x*x\n",
    "\n",
    "spark.udf.register('myfunc',f2,IntegerType())\n",
    "myfunc = udf(f2,IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "45e038a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def convertCase(str):\n",
    "    resStr=\"\"\n",
    "    arr = str.split(\" \")\n",
    "    for x in arr:\n",
    "       resStr= resStr + x[0:1].upper() + x[1:len(x)] + \" \"\n",
    "    return resStr\n",
    "\n",
    "convertUDF = udf(lambda z: convertCase(z),StringType())\n",
    "convertUDF = udf(lambda z: convertCase(z)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f4aeabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew = dfnew.withColumn('katainewtimestamp',current_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "abda8ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+---------+-----------------+\n",
      "|userId|movieId|rating| timestamp|ratingStr|katainewtimestamp|\n",
      "+------+-------+------+----------+---------+-----------------+\n",
      "|     1|     39|   2.6|1260759144|      one|       2022-09-25|\n",
      "|     1|     35|   4.9|1260759148|     five|       2022-09-25|\n",
      "+------+-------+------+----------+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfnew.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "7fcb199c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'(2) PythonRDD[248] at collect at C:\\\\Users\\\\W10\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_11192\\\\1450628862.py:1 []\\n |  C:/Users/W10/Desktop/sparkTxt/spark.txt MapPartitionsRDD[245] at textFile at NativeMethodAccessorImpl.java:0 []\\n |  C:/Users/W10/Desktop/sparkTxt/spark.txt HadoopRDD[244] at textFile at NativeMethodAccessorImpl.java:0 []'"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a048da18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [userId#2581, movieId#2582, rating#2583, timestamp#2584, ratingStr#2585, 19261 AS katainewtimestamp#2622]\n",
      "+- *(1) Filter AtLeastNNulls(n, userId#2581,movieId#2582,rating#2583,timestamp#2584,ratingStr#2585)\n",
      "   +- FileScan csv [userId#2581,movieId#2582,rating#2583,timestamp#2584,ratingStr#2585] Batched: false, DataFilters: [AtLeastNNulls(n, userId#2581,movieId#2582,rating#2583,timestamp#2584,ratingStr#2585)], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/W10/Desktop/sparkTxt/rating2.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<userId:string,movieId:string,rating:string,timestamp:string,ratingStr:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfnew.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf4d1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
